{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# J.P. Morgan Quantitative Research Experience\n",
    "This online course gave me an insightful experience into a day in the life of someone carrying out a quant role at J.P. Morgan. The first task focused on predicting the price of oil, and then task 2 built on this, requiring us to derive the value of an oil contract using our future price predictions. Task 3 asked us to build a Probability of Default model, which took various customer factors such as number of credit lines and credit score and then output a probability of the customer not being able to pay back the loan. I experimented with regression but went for a Decision Tree and further a Random Forest, which takes the average of many Decision Trees. This gave less extreme probability estimates while still making very accurate predictions. Here I will go into task 4 in detail, which required us to quantise the FICO scores, grouping them into bands or rangesâ€”to make them a stronger statistic when we use them in a Probability of Default function, for example.\n",
    "# Task 4: Bucket FICO Scores\n",
    "The input for our problem was a list of FICO scores and the number of buckets these needed to be filtered into. We needed to return optimised boundaries for these buckets such that scores in each respective bucket were as close to each other as possible. One method we were given to achieve this is by using the Mean Squared Error. We needed to find a bucket arrangement such that the total difference from each FICO score and it's respective Bucket midpoint is minimised. The MSE is a sufficient statistic for this.\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "## Method\n",
    "\n",
    "- **Step 1:** Sort the FICO scores and count how many times they appeared.\n",
    "- **Step 2:** Compute the sum of squared errors (SSE) for every possible interval of unique scores.\n",
    "- **Step 3:** We set up two matrices the first called dp which we fill with infinity (np.inf) because we are searching for a minimum SSE. If we find better we replace with our improved value. The second matrix bucket_index will store the index of where our last bucket needs to start for our most optimal arrangement.\n",
    "- **Step 4:** We loop over each number of scores and number of buckets pair (i,k), each time we find the optimal SSE by splitting j scores into k-1 buckets, and the remaining scores into the kth bucket. We will always already have the optimal value of splitting j scores into k-1 buckets for all j less than i and so we just take the j with lowest total SSE\n",
    "$$\n",
    "\\text{cost} = dp[j][k-1] + sse[j][i-1]\n",
    "$$\n",
    "- **Step 5:** Our bucket_index matrix now tells us where the last bucket should be to minimise SSE for each number of score/bucket combination. So from here we backtrack: find the index of where the last bucket should be for k buckets. We take the score at this index to find one of our boundaries and then go back to our table and find the last bucket_index for all scores below this boundary and k-1 buckets. This repeats until k=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T13:45:57.382564Z",
     "iopub.status.busy": "2025-08-12T13:45:57.382385Z",
     "iopub.status.idle": "2025-08-12T13:45:59.328084Z",
     "shell.execute_reply": "2025-08-12T13:45:59.326901Z",
     "shell.execute_reply.started": "2025-08-12T13:45:57.382547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "loan_data = pd.read_csv('JP_Morgan/Task 3 and 4_Loan_Data.csv')\n",
    "scores = np.sort(loan_data[\"fico_score\"])\n",
    "\n",
    "def quantize_fico(K):\n",
    "    values, counts = np.unique(scores, return_counts=True)\n",
    "    n = len(values)\n",
    "    \n",
    "    # We compute SSE for every interval of scores\n",
    "    sse = np.zeros((n, n))\n",
    "    for start in range(n):\n",
    "        score_sum = 0\n",
    "        total_count = 0\n",
    "        for end in range(start, n):\n",
    "            score_sum += values[end] * counts[end]\n",
    "            total_count += counts[end]\n",
    "            mean = score_sum / total_count\n",
    "            sse[start][end] = np.sum(counts[start:end+1] * (values[start:end+1] - mean)**2)\n",
    "    \n",
    "    # DP table: dp[i][k] will be the minimum SSE for first i scores into k buckets\n",
    "    dp = np.full((n+1, K+1), np.inf)\n",
    "    #SSE for 0 scores and zero buckets is zero\n",
    "    dp[0][0] = 0\n",
    "    #bucket_index will give the index in scores where the last bucket starts for each i k combination\n",
    "    bucket_index = np.zeros((n+1, K+1), dtype=int)\n",
    "    \n",
    "    #We find the optimal bucket arrangement for with the first scores and then use dynamic programming whilst adding more scores to find the optimal arrangement\n",
    "    for i in range(1, n+1):\n",
    "        for k in range(1, min(i, K)+1):\n",
    "            for j in range(k-1, i):\n",
    "                #cost is minimum SSE achievable with j scores and k-1 buckets + the SSE from if we put the bucket at index j\n",
    "                cost = dp[j][k-1] + sse[j][i-1]\n",
    "                #If this is the best SSE found so far we store the cost to beat and the index at where the last bucket should now be placed\n",
    "                if cost < dp[i][k]:\n",
    "                    dp[i][k] = cost\n",
    "                    bucket_index[i][k] = j\n",
    "\n",
    "    # Backtrack through the table to find bucket boundaries\n",
    "    boundaries = []\n",
    "    i, k = n, K\n",
    "    while k > 0:\n",
    "        j = bucket_index[i][k]\n",
    "        boundaries.append((values[j], values[i-1]))\n",
    "        i = j\n",
    "        k = k-1\n",
    "    boundaries.reverse()\n",
    "    \n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The test case below where we use 5 buckets gives us optimal boundaries to use for each bucket. This now gives us a rating system where if we had someone's credit score we can give it a specific number rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(408, 552), (553, 607), (608, 654), (655, 706), (707, 850)]\n"
     ]
    }
   ],
   "source": [
    "#Test case\n",
    "K = 5  \n",
    "boundaries = quantize_fico(K)\n",
    "boundaries = [(int(low), int(high)) for low, high in boundaries]\n",
    "print(boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "We'll quickly draft a simpler method where for 5 buckets we take 5 equidistant quantiles to divide the scores up and give us our boundaries. When we calculate the total MSE when using each method we are assured our method using dynamic programming is better, with an MSE about 53% smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465.172675\n",
      "689.416575\n"
     ]
    }
   ],
   "source": [
    "def total_mse(bucket_boundaries):\n",
    "    total = 0\n",
    "    for score in scores:\n",
    "        for (low, high) in bucket_boundaries:\n",
    "            if low <= score <= high:\n",
    "                bucket_mid = (low + high) / 2\n",
    "                total += (score - bucket_mid) ** 2\n",
    "                break\n",
    "    mse = total / len(scores)\n",
    "    return mse\n",
    "    \n",
    "n = len(scores)\n",
    "quantile_indices = [0, n//5, 2*n//5, 3*n//5, 4*n//5, n]\n",
    "quantile_boundaries = []\n",
    "bucket_mean = []\n",
    "for i in range(5):\n",
    "    bucket_scores = scores[quantile_indices[i]:quantile_indices[i+1]]\n",
    "    min_score = bucket_scores[0]\n",
    "    max_score = bucket_scores[-1]\n",
    "    quantile_boundaries.append((min_score, max_score))\n",
    "quantile_boundaries = [(int(low), int(high)) for low, high in quantile_boundaries]\n",
    "print(total_mse(quantile_boundaries))\n",
    "print(total_mse(boundaries))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
